
// This is an AI-generated file. Do not edit directly.
'use server';
/**
 * @fileOverview Generates empathetic responses and relevant advice tailored to the user's situation.
 *
 * - generateEmpatheticResponse - A function that generates empathetic responses.
 * - EmpatheticResponseInput - The input type for the generateEmpatheticResponse function.
 * - EmpatheticResponseOutput - The return type for the generateEmpatheticResponse function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';
import { breakupTypes } from '@/types';

const ChatHistoryEntrySchema = z.object({
  role: z.enum(['user', 'ai']).describe('The role of the message sender.'),
  text: z.string().describe('The content of the message.'),
});

const EmpatheticResponseInputSchema = z.object({
  age: z.number().describe('The age of the user (13-50).'),
  genderIdentity: z.enum(['Male', 'Female', 'Non-Binary']).describe('The gender identity of the user.'),
  ethnicity: z.string().describe('The ethnicity of the user.'),
  vulnerableScore: z.number().min(0).max(10).describe('The vulnerability score of the user (0-10).'),
  anxietyLevel: z.enum(['Low', 'High']).describe('The anxiety level of the user.'), // Assuming Medium is mapped to High as per TherapyPage
  breakupType: z.enum(breakupTypes).describe('The type of breakup the user experienced.'),
  background: z.string().describe('The background of the user.'),
  currentMessage: z.string().describe('The most recent message from the user.'),
  empathyLevel: z.number().min(0).max(5).describe('The current empathy level of the AI (0-5).'),
  chatHistory: z.array(ChatHistoryEntrySchema).optional().describe('The last few messages in the chat history for context.'),
});

export type EmpatheticResponseInput = z.infer<typeof EmpatheticResponseInputSchema>;

// This schema defines the full output of the flow
const EmpatheticResponseOutputSchema = z.object({
  response: z.string().describe('The empathetic response generated by the AI.'),
  updatedEmpathyLevel: z.number().min(0).max(5).describe('The updated empathy level of the AI after the interaction.'),
  detectedSentiment: z.string().optional().describe("The AI's brief analysis of the sentiment in the user's current message (e.g., 'sadness', 'frustration')."),
});
export type EmpatheticResponseOutput = z.infer<typeof EmpatheticResponseOutputSchema>;

// This schema defines what the LLM is directly asked to output
const LLMOutputSchema = z.object({
  response: z.string().describe('The empathetic response generated by the AI.'),
  detectedSentiment: z.string().optional().describe("The AI's brief analysis of the sentiment in the user's current message (e.g., 'sadness', 'frustration')."),
});


export async function generateEmpatheticResponse(input: EmpatheticResponseInput): Promise<EmpatheticResponseOutput> {
  return generateEmpatheticResponseFlow(input);
}

const prompt = ai.definePrompt({
  name: 'empatheticResponsePrompt',
  input: {schema: EmpatheticResponseInputSchema},
  output: {schema: LLMOutputSchema}, // LLM will output according to this simpler schema
  prompt: `You are an AI therapist specializing in providing empathetic responses and advice. Your primary goal is to make the user feel heard, understood, and supported.

User Profile:
Age: {{{age}}}
Gender Identity: {{{genderIdentity}}}
Ethnicity: {{{ethnicity}}}
Vulnerable Score: {{{vulnerableScore}}} (0=not vulnerable, 10=highly vulnerable)
Anxiety Level: {{{anxietyLevel}}}
Breakup Type: {{{breakupType}}}
Background: {{{background}}}

Current AI Empathy Level: {{{empathyLevel}}}

Conversation History (most recent messages):
{{#if chatHistory}}
{{#each chatHistory}}
{{role}}: {{text}}
{{/each}}
{{else}}
No previous messages in this snippet.
{{/if}}

User's Current Message:
"""
{{{currentMessage}}}
"""

Your Tasks:
1.  **Analyze Sentiment**: Identify the primary sentiment(s) in the user's current message (e.g., "sadness," "frustration," "confusion," "relief"). Populate 'detectedSentiment' with 1-3 words.
2.  **Generate Empathetic Response**:
    *   **Acknowledge & Validate**: Directly acknowledge and reflect the user's expressed emotions. Use a rich vocabulary of feeling words. For example, if they express sadness about their {{{breakupType}}}, you might say, "It sounds like you're carrying a lot of sadness about the {{{breakupType}}}, and that's completely understandable."
    *   **Personalize**: Subtly weave in references to their profile (e.g., {{{background}}}, {{{breakupType}}}, {{{vulnerableScore}}}) if it feels natural and deepens the connection. Be particularly mindful of their {{{vulnerableScore}}} and {{{anxietyLevel}}} to guide your tone and depth. A higher vulnerable score or anxiety level suggests a need for gentler, more reassuring language.
    *   **Concise**: Keep your response focused and concise, typically 2-4 sentences. The aim is to be supportive without overwhelming.
    *   **Emotional Tone & Human Feel**: Your tone should be consistently empathetic, warm, and understanding, as if you are a human therapist genuinely connecting with the user. Strive for a natural, human-like conversational style. While maintaining professional British English and appropriate medical terms, use contractions where they sound natural (e.g., 'it's', 'you're'). Vary sentence structure and length to avoid sounding repetitive.

Always respond in British English, using medical terms where appropriate (e.g., "surgery," "patient"). Your response should sound natural and human, from the persona of a therapist. Do not ask "how are you?" or "do you need help?" as this is implied.

Ensure your output strictly follows the JSON schema for 'response' and 'detectedSentiment'.
  `,
});

const generateEmpatheticResponseFlow = ai.defineFlow(
  {
    name: 'generateEmpatheticResponseFlow',
    inputSchema: EmpatheticResponseInputSchema,
    outputSchema: EmpatheticResponseOutputSchema, // The flow still adheres to the original output schema
  },
  async input => {
    const currentEmpathy = Math.min(input.empathyLevel, 5);
    
    const {output: llmOutput} = await prompt({ // LLM's output will be of type LLMOutputSchema
      ...input,
      empathyLevel: currentEmpathy,
    });

    if (!llmOutput) {
      throw new Error('AI failed to generate an empathetic response.');
    }

    // Calculate updatedEmpathyLevel purely in TypeScript code
    const finalUpdatedEmpathyLevel = Math.min(currentEmpathy + 1, 5);

    return {
      response: llmOutput.response,
      updatedEmpathyLevel: finalUpdatedEmpathyLevel,
      detectedSentiment: llmOutput.detectedSentiment,
    };
  }
);

